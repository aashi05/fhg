{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'office', u'graduate', u'president', u'community', u'organizer', u'law', u'degree', u'rights', u'attorney', u'terms', u'attention', u'campaign', u'victory', u'primary', u'address', u'election', u'delegates', u'primaries', u'nomination', u'nominee', u'Nobel Peace Prize', u'months', u'inauguration', u'laureate', u'the Tax Relief, Unemployment Insurance Reauthorization, and Job Creation Act', u'years', u'stimulus', u'legislation', u'response', u'Recession', u'form', u'initiatives', u'term', u'the Iraq War', u'New START', u'policy', u'involvement', u'troop', u'levels', u'arms', u'treaty', u'opposition', u'operation', u'death', u'bin', u'control', u'total', u'seats', u'the Budget Control Act', u'debate', u'spending', u'nation', u'debt', u'limit', u'policies', u'gun', u'shooting', u'inclusiveness', u'LGBT', u'administration', u'briefs', u'part', u'state', u'level', u'sex', u'marriage', u'bans', u'intervention', u'gains', u'withdrawal', u'process', u'combat', u'operations', u'relations']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "en_nlp = spacy.load(\"en\")\n",
    "i=0\n",
    "person_list=[]\n",
    "location_list=[]\n",
    "number_list=[]\n",
    "entity_list=[]\n",
    "import pickle\n",
    "#pickle_path = 'picklepath.pkl'\n",
    "\n",
    "corpusFile = open(\"corpus.txt\",\"r\") \n",
    "data = corpusFile.read() \n",
    "corpusFile.close() \n",
    "data = data.split(\".\" or \"!\" or \"?\")\n",
    "for sent in data:\n",
    "    en_doc = en_nlp(u'' + sent)\n",
    "    for ent in en_doc.ents:\n",
    "        if ent.label_ == \"PERSON\" or ent.label_ == \"NORP\" or ent.label_==\"ORG\":\n",
    "            person_list.append(ent.text)\n",
    "#print(person_list)\n",
    "for sent in data:\n",
    "    en_doc = en_nlp(u'' + sent)\n",
    "    for ent in en_doc.ents:\n",
    "        if ent.label_ == \"LOC\" or ent.label_==\"GPE\" or ent.label_==\"FAC\" or ent.label_ == \"ORG\":\n",
    "            location_list.append(ent.text)\n",
    "#print(location_list)\n",
    "for sent in data:\n",
    "    en_doc = en_nlp(u'' + sent)\n",
    "    for ent in en_doc.ents:\n",
    "        if ent.label_ == \"DATE\" or ent.label_==\"PERCENT\" or ent.label_==\"TIME\" or ent.label_==\"QUANTITY\" or ent.label_==\"ORDINAL\" or ent.label_==\"CARDINAL\":\n",
    "            number_list.append(ent.text)\n",
    "#print(number_list)\n",
    "for sent in data:\n",
    "    en_doc = en_nlp(u'' + sent)\n",
    "    for ent in en_doc.ents:\n",
    "        if ent.label_ == \"PRODUCT\" or ent.label_==\"EVENT\" or ent.label_==\"WORK_OF_ART\" or ent.label_==\"LAW\" or ent.label_==\"LANGUAGE\":\n",
    "            entity_list.append(ent.text)\n",
    "    for token in en_doc:\n",
    "        if token.pos_==\"NOUN\":\n",
    "            if token.text not in person_list and token.text not in number_list and token.text not in location_list and token.text not in entity_list:\n",
    "                entity_list.append(token.text)\n",
    "print(entity_list)\n",
    "with open('picklepath.pkl', 'wb') as f:\n",
    "    pickle.dump(entity_list, f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'noun, proper singular'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "en_nlp = spacy.load('en')\n",
    "doc = en_nlp(u'Sarah was driving')\n",
    "spacy.explain(\"NNP\")\n",
    "#spacy.explain(\"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
