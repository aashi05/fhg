{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would you like to know?\"What was her problem\"\n",
      "[u'HUM']\n"
     ]
    }
   ],
   "source": [
    "import pandas \n",
    "import spacy \n",
    "import scipy \n",
    "import sklearn \n",
    "import pickle\n",
    "from sklearn import externals \n",
    "from sklearn import svm \n",
    "from sklearn.svm import LinearSVC \n",
    "from scipy import sparse \n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.externals import joblib\n",
    " \n",
    "def remove_irrelevant_features(df_question): \n",
    "    df_question_class = df_question.pop('Class') \n",
    "\n",
    " \n",
    "    df_question.pop('Question') \n",
    "    #df_question.pop('WH-Bigram') \n",
    "\n",
    " \n",
    "    return df_question_class \n",
    "\n",
    " \n",
    "def pre_process(dta): \n",
    "    return pandas.get_dummies(dta) \n",
    "\n",
    " \n",
    "def transform_data_matrix(df_question_train, df_question_predict): \n",
    "\n",
    " \n",
    "    df_question_train_columns = list(df_question_train.columns) \n",
    "    df_question_predict_columns = list(df_question_predict.columns) \n",
    "\n",
    " \n",
    "    df_question_trans_columns = list(set(df_question_train_columns + df_question_predict_columns)) \n",
    "\n",
    " \n",
    "    trans_data_train = {} \n",
    "\n",
    " \n",
    "    for feature in df_question_trans_columns: \n",
    "        if feature not in df_question_train: \n",
    "            trans_data_train[feature] = [0 for i in range(len(df_question_train.index))] \n",
    "        else: \n",
    "            trans_data_train[feature] = list(df_question_train[feature]) \n",
    "\n",
    " \n",
    "    df_question_train = pandas.DataFrame(trans_data_train) \n",
    "    df_question_train = csr_matrix(df_question_train) \n",
    "\n",
    " \n",
    "    trans_data_predict = {} \n",
    "\n",
    " \n",
    "    for feature in trans_data_train: \n",
    "        if feature not in df_question_predict: \n",
    "            trans_data_predict[feature] = 0 \n",
    "        else: \n",
    "            trans_data_predict[feature] = list(df_question_predict[feature])   \n",
    "\n",
    " \n",
    "    df_question_predict = pandas.DataFrame(trans_data_predict) \n",
    "    df_question_predict = csr_matrix(df_question_predict) \n",
    "\n",
    " \n",
    "    return df_question_train, df_question_predict \n",
    "\n",
    " \n",
    "def get_question_predict_data(en_doc): \n",
    "    sentence_list = list(en_doc.sents)[0:1] \n",
    "    en_nlp = spacy.load(\"en_core_web_md\") \n",
    "\n",
    " \n",
    "    question_data_frame = [] \n",
    "\n",
    " \n",
    "    for sentence in sentence_list: \n",
    "\n",
    " \n",
    "        wh_bi_gram = [] \n",
    "        root_token, wh_pos, wh_nbor_pos, wh_word = [\"\"] * 4 \n",
    "        for token in sentence: \n",
    "\n",
    " \n",
    "        # if token is of WH question type \n",
    "            if token.tag_ == \"WDT\" or token.tag_ == \"WP\" or token.tag_ == \"WP$\" or token.tag_ == \"WRB\": \n",
    "                wh_pos = token.tag_ \n",
    "                wh_word = token.text \n",
    "                wh_bi_gram.append(token.text) \n",
    "                wh_bi_gram.append(str(en_doc[token.i + 1])) \n",
    "                wh_nbor_pos = en_doc[token.i + 1].tag_ \n",
    "     \n",
    "            # if token is the root of sentence \n",
    "            if token.dep_ == \"ROOT\": \n",
    "                root_token = token.tag_ \n",
    "     \n",
    "        question_data_frame_obj = {'WH': wh_word, 'WH-POS': wh_pos, 'WH-NBOR-POS': wh_nbor_pos, 'Root-POS': root_token} \n",
    "        question_data_frame.append(question_data_frame_obj) \n",
    "         \n",
    "        df_question = pandas.DataFrame(question_data_frame) \n",
    "\n",
    " \n",
    "    return df_question \n",
    "\n",
    " \n",
    "def support_vector_machine(df_question_train, df_question_class, df_question_predict): \n",
    "    lin_clf = LinearSVC() \n",
    "    lin_clf.fit(df_question_train, df_question_class) \n",
    "    prediction = lin_clf.predict(df_question_predict) \n",
    "    return prediction, lin_clf \n",
    "\n",
    " \n",
    "def classify_question(en_doc): \n",
    "    training_data_path = \"qclassify.csv\" \n",
    "    df_question_train = pandas.read_csv(training_data_path, sep='|', header=0, encoding='utf-8') \n",
    "     \n",
    "    df_question_class = remove_irrelevant_features(df_question_train) \n",
    "    df_question_predict = get_question_predict_data(en_doc) \n",
    "    df_question_train = pre_process(df_question_train)\n",
    "    #joblib.dump(df_question_train, \"training_data_set.pkl\")\n",
    "    f = open('training_data_set.pkl', 'wb')\n",
    "    pickle.dump(df_question_train, f)\n",
    "    f.close()\n",
    "    f1 = open('training_data_classes.pkl', 'wb')\n",
    "    pickle.dump(df_question_class, f1)\n",
    "    f1.close()\n",
    "    df_question_predict = pre_process(df_question_predict) \n",
    "     \n",
    "    df_question_train, df_question_predict = transform_data_matrix(df_question_train, df_question_predict) \n",
    "    predicted_class, svc_clf = support_vector_machine(df_question_train, df_question_class, df_question_predict) \n",
    "    print (predicted_class) \n",
    "    return svc_clf  \n",
    "if __name__ == \"__main__\": \n",
    "\n",
    " \n",
    "    en_nlp_l = spacy.load(\"en_core_web_md\") \n",
    "    question = input(\"What would you like to know?\")\n",
    "    question = str(question)\n",
    "    en_doc_l = en_nlp_l(u'' + question)\n",
    "    #model_pickle_path = 'model_pickle.pkl'\n",
    "    classifier = classify_question(en_doc_l)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'wh-determiner'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.explain(\"WDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
